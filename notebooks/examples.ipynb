{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbe593-c506-4c8d-9135-1df8d7d1e55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be63c6-c121-400d-b524-eaffb35610d2",
   "metadata": {},
   "source": [
    "# xweights' example notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b63cf",
   "metadata": {},
   "source": [
    "This notbook shows some examples how to use xweights. We want to calculate time series of spatial averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9566f73",
   "metadata": {},
   "source": [
    "## 1) Read input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432417e",
   "metadata": {},
   "source": [
    "In the first step, read the input data from disk and create a dataset dictionary. The values of the dataset dictionary are the xarray DataSets read from the input, the keys denote the corresponding dataset names. If you have enough computational ressources you can use large intake-esm catalogue files as input too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068e52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "import xweights as xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1773c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netcdffile = (\n",
    "    \"tas_EUR-11_MIROC-MIROC5_rcp85_r1i1p1_CLMcom-CCLM4-8-17_v1_mon_200601-201012.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600f12c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(netcdffile)\n",
    "dataset_dict = {\"tas_EUR-11_MIROC-MIROC5_rcp85_r1i1p1_CLMcom-CCLM4-8-17_v1_mon\": ds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a1299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, ds in dataset_dict.items():\n",
    "    break\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ee596",
   "metadata": {},
   "source": [
    "## 2) Get some xweights information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516feb97",
   "metadata": {},
   "source": [
    "xweights contains some pre-defined regions. Each region contains a geopandas GeoDataFrmae with several geometries. The pre-defined regions are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad39617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efca21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_subregions(\"states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b69008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_subregions(\"counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177df6d0-b6a1-4425-9a40-0e17a11bee11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_subregions(\"counties_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cc0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_subregions(\"prudence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fe038-9c73-407b-85ae-d3c09dab9e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xw.which_subregions(\"ipcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49643b20",
   "metadata": {},
   "source": [
    "## 3) Choose a region "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa54247",
   "metadata": {},
   "source": [
    "Now, let's focus on German 'Bundesländer'. We read in the data as geopandas GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709f3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bdl = xw.get_region(\"states\")\n",
    "bdl.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61fbb5",
   "metadata": {},
   "source": [
    "Of course, you can select singel geometries. Let's take Schleswig-Holstein, Hamburg, Bremen and Lower Saxony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16d76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bdl_sub = xw.get_region(\n",
    "    \"states\",\n",
    "    name=[\"01_Schleswig-Holstein\", \"02_Hamburg\", \"03_Niedersachsen\", \"04_Bremen\"],\n",
    ")\n",
    "bdl_sub.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4111c",
   "metadata": {},
   "source": [
    "Now, we combine those four geometries to one new geometry called 'NothSeaCoast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e97620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsc = xw.get_region(\n",
    "    \"states\",\n",
    "    name=[\"01_Schleswig-Holstein\", \"02_Hamburg\", \"03_Niedersachsen\", \"04_Bremen\"],\n",
    "    merge=[\"all\", \"NothSeaCoast\"],\n",
    ")\n",
    "nsc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ae97c",
   "metadata": {},
   "source": [
    "You can read your own shapefile as region file. Then, you have to specify a column name. This column name helps xweights to differentiate the shp file. The example shpfile contains geometries of Neusiedel am See, a small town in Austria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdc61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shpfile = \"Seewinkel_map/Seewinkel.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91685e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom = xw.get_region(shpfile, column=\"VA\")\n",
    "custom.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd938d",
   "metadata": {},
   "source": [
    "Here again, you can merge all this small geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3a669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom = xw.get_region(shpfile, column=\"VA\", merge=\"VA\")\n",
    "custom.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f5b076",
   "metadata": {},
   "source": [
    "## 4) Calculate a time series of patial averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07992b",
   "metadata": {},
   "source": [
    "Now, we can calculate a time series of spatial averages using a xarray dataset and geopandas GeoDataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f0b36",
   "metadata": {},
   "source": [
    "Here for all 'Bundesländer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c849f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_bdl = xw.spatial_averaging(ds, bdl)\n",
    "out_bdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d55fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_bdl[\"tas\"].plot(col=\"geom\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8ac27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_nsc = xw.spatial_averaging(ds, nsc)\n",
    "out_nsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef1c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_nsc.tas.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c3ec3c",
   "metadata": {},
   "source": [
    "Ok, that's not pretty exciting I know :/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1c7ea",
   "metadata": {},
   "source": [
    "## 5) Consider land points only "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859c508",
   "metadata": {},
   "source": [
    "With xesmf it is very easy to consider land points only. You just have to add a land-sea mask to the xarray Dataset. xesmf automatically considers the mask whil calculating spatial averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023b639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "lsmfile = \"sftlf_EUR-11_MIROC-MIROC5_rcp85_r0i0p0_CLMcom-CCLM4-8-17_v1_fx.nc\"\n",
    "lsm = xr.open_dataset(lsmfile)\n",
    "lsm[\"sftlf\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da95382",
   "metadata": {},
   "source": [
    "We need to normalize the land-sea mask to the values 0 ant 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be13c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lsm_norm = xr.where(lsm[\"sftlf\"] > 0, 50, 0)\n",
    "lsm_norm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e07f9",
   "metadata": {},
   "source": [
    "Now, let's add this mask to our dataset. And calculat for the PRUDENCE regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4a130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_lsm = ds.copy()\n",
    "ds_lsm[\"mask\"] = lsm_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df1997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prudence = xw.get_region(\"prudence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c23552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_prudence = xw.spatial_averaging(ds, prudence)\n",
    "out_prudence_lsm = xw.spatial_averaging(ds_lsm, prudence)\n",
    "out_prudence_lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b55ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_prudence[\"tas\"].plot(col=\"geom\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12045b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_prudence_lsm[\"tas\"].plot(col=\"geom\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f8f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(out_prudence[\"tas\"] - out_prudence_lsm[\"tas\"]).plot(col=\"geom\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e96bff",
   "metadata": {},
   "source": [
    "## 6) Save results to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4630d43",
   "metadata": {},
   "source": [
    "We can simplify the above steps and use a new the function. The result will be written to a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bbe0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = xw.compute_weighted_means_ds(ds, region=\"prudence\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372003e",
   "metadata": {},
   "source": [
    "Let's use some paramters to adjust the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e7e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = xw.compute_weighted_means_ds(\n",
    "    ds,\n",
    "    region=\"prudence\",\n",
    "    ds_name=\"tas_EUR-11_MIROC-MIROC5_rcp85_r1i1p1_CLMcom-CCLM4-8-17_v1_mon\",\n",
    "    column_names=[\n",
    "        \"institute_id\",\n",
    "        \"driving_model_id\",\n",
    "        \"experiment_id\",\n",
    "        \"driving_model_ensemble_member\",\n",
    "        \"model_id\",\n",
    "        \"rcm_version_id\",\n",
    "        \"standard_name\",\n",
    "        \"units\",\n",
    "    ],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691aec4",
   "metadata": {},
   "source": [
    "Now, with a pandas DataFrame feel free to do a lots of statistics :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25e36a",
   "metadata": {},
   "source": [
    "Set the parameter ``output`` to a file name and save the DataFrame on disk. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ad6e2",
   "metadata": {},
   "source": [
    "## 7) All in one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3eb41e",
   "metadata": {},
   "source": [
    "Besides ``xw.compute_weighted_means_ds`` there is another function called ``xw.compute_weighted_means``. This function combines all above steps to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26f1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = xw.compute_weighted_means(\n",
    "    dataset_dict,\n",
    "    region=\"prudence\",\n",
    "    column_names=[\n",
    "        \"institute_id\",\n",
    "        \"driving_model_id\",\n",
    "        \"experiment_id\",\n",
    "        \"driving_model_ensemble_member\",\n",
    "        \"model_id\",\n",
    "        \"rcm_version_id\",\n",
    "        \"standard_name\",\n",
    "        \"units\",\n",
    "    ],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a3a1b",
   "metadata": {},
   "source": [
    "As mentioned above, if you have enough computational ressources you can use an intake-esm catalogue file as input instead of one single netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64247bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
